import streamlit as st
import google.generativeai as genai
import os
from PIL import Image

# --- 1. è¨­å®šèˆ‡è®€å–çŸ¥è­˜åº« ---
st.set_page_config(page_title="YG äººé¡åœ–å…¨èƒ½å¤§è…¦", layout="wide")

@st.cache_data(show_spinner=False)
def get_knowledge_base():
    base_path = os.path.dirname(os.path.abspath(__file__))
    file_path = os.path.join(base_path, "knowledge_base.txt")
    if os.path.exists(file_path):
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception as e:
            st.error(f"è®€å–æª”æ¡ˆå¤±æ•—: {e}")
    return None

knowledge_context = get_knowledge_base()

# --- 2. å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("ğŸ”‘ ç³»çµ±è¨­å®š")
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
        st.success("âœ… API é‡‘é‘°å·²è¼‰å…¥")
    else:
        api_key = st.text_input("è«‹è¼¸å…¥ Gemini API Key", type="password")
    
    st.divider()
    st.caption("ç‰ˆæœ¬ï¼š2.5 (æµé‡ç©©å®šç‰ˆ)")
    st.caption("ä½œè€…ï¼šææ™é§’ (YG)")

# --- 3. ä¸»ç•«é¢ ---
st.title("ğŸ›¡ï¸ äººé¡åœ–å…¨è‡ªå‹•è§£ç­”ç³»çµ±ï¼šè·æ¶¯è²¡è³¦ç‰ˆ")

tab_manual, tab_ai = st.tabs(["âœï¸ æ‰‹å‹•è¼¸å…¥åˆ†æ", "ğŸ“¸ æˆªåœ–è‡ªå‹•è¾¨è­˜"])

with tab_manual:
    st.subheader("è«‹è¼¸å…¥æ•¸æ“š")
    c1, c2 = st.columns(2)
    with c1:
        u_type = st.selectbox("1. æ‚¨çš„é¡å‹", ["ç”Ÿç”¢è€…", "é¡¯ç¤ºç”Ÿç”¢è€…", "æŠ•å°„è€…", "é¡¯ç¤ºè€…", "åæ˜ è€…"])
        u_auth = st.text_input("2. å…§åœ¨æ¬Šå¨")
    with c2:
        u_ch = st.text_input("3. é€šé“æ•¸å­—")
        u_gt = st.text_input("4. é–˜é–€æ•¸å­—")

    user_query = st.text_area("ğŸ’¬ æ‚¨ç‰¹åˆ¥æƒ³å•ä»€éº¼ï¼Ÿ", placeholder="ä¾‹å¦‚ï¼šæˆ‘æƒ³æœˆå…¥ 30 è¬è©²æ€éº¼åšï¼Ÿ")

    if st.button("ğŸš€ å•Ÿå‹• AI å¤§è…¦æ·±åº¦åˆ†æ", use_container_width=True):
        if not api_key:
            st.error("âŒ è«‹å…ˆè¨­å®š API é‡‘é‘°")
        elif not knowledge_context:
            st.error("âŒ æ‰¾ä¸åˆ°çŸ¥è­˜åº«æª”æ¡ˆ")
        else:
            with st.spinner("AI æ­£åœ¨ç¿»é–± 7 æœ¬æ–‡ç»ï¼Œè«‹ç¨å€™..."):
                try:
                    genai.configure(api_key=api_key)
                    model = genai.GenerativeModel('gemini-2.0-flash')
                    
                    # ã€é—œéµå„ªåŒ–ã€‘ï¼šå°‡ context é™åˆ¶åœ¨ 15 è¬å­—å…ƒå…§
                    # é€™å¤§ç´„ç­‰æ–¼ 20-30 è¬ Tokenï¼Œèƒ½ç¢ºä¿åœ¨å…è²»ç‰ˆçš„ TPM (æ¯åˆ†é˜ Token é™åˆ¶) å…§å®‰å…¨é‹ä½œ
                    safe_context = knowledge_context[:150000] 
                    
                    prompt = f"""
                    ä½ æ˜¯ä¸€ä½ç²¾é€šäººé¡åœ–è·æ¶¯èˆ‡è²¡å¯Œçš„å°å¸«ã€‚
                    è«‹æ ¹æ“šé€™ä»½æ–‡ç»ç²¾è¯å…§å®¹å›ç­”ï¼š
                    --- æ–‡ç»é–‹å§‹ ---
                    {safe_context}
                    --- æ–‡ç»çµæŸ ---
                    
                    ä½¿ç”¨è€…æ•¸æ“šï¼š
                    é¡å‹ï¼š{u_type} / æ¬Šå¨ï¼š{u_auth} / é€šé“ï¼š{u_ch} / é–˜é–€ï¼š{u_gt}
                    
                    å•é¡Œï¼š{user_query}
                    
                    è«‹çµ¦å‡ºæ¥µå…¶å…·é«”ã€æ ¹æ“šæ›¸ä¸­é‚è¼¯çš„è·æ¶¯èˆ‡è³ºéŒ¢å»ºè­°ã€‚è«‹ä»¥ç¹é«”ä¸­æ–‡å›ç­”ã€‚
                    """
                    
                    response = model.generate_content(prompt)
                    st.success("### ğŸ“œ æ·±åº¦åˆ†æå ±å‘Š")
                    st.markdown(response.text)
                except Exception as e:
                    if "429" in str(e):
                        st.error("âš ï¸ ç›®å‰æµé‡æ“æ“ ï¼è«‹ã€ç­‰å¾… 60 ç§’ã€å¾Œå†æŒ‰ä¸€æ¬¡æŒ‰éˆ•ï¼Œé€™æ˜¯å…è²»ç‰ˆ API çš„é™åˆ¶ã€‚")
                    else:
                        st.error(f"ç³»çµ±åˆ†æå¤±æ•—ï¼š{e}")

# è¾¨è­˜åˆ†é éƒ¨åˆ†é‚è¼¯ç›¸åŒï¼Œå»ºè­°åŒæ­¥ä¿®æ”¹æ¨¡å‹åç¨±ç‚º gemini-2.0-flash
